# 第三天基本功能

|      |      |
| ---- | ---- |
|      |      |
|      |      |
|      |      |
|      |      |
|      |      |
|      |      |
|      |      |
|      |      |
|      |      |
|      |      |
|      |      |
|      |      |
|      |      |
|      |      |
|      |      |
|      |      |
|      |      |
|      |      |
|      |      |
|      |      |

### 基本功能

~~~python
index = pd.date_range('1/1/2000', periods=8)
#一维矩阵
s = pd.Series(np.random.randn(5), index=['a', 'b', 'c', 'd', 'e'])
#二维矩阵
df = pd.DataFrame(np.random.randn(8, 3), index=index,columns=['A','B', 'C'])
#三维矩阵
wp = pd.Panel(np.random.randn(2, 5, 4), items=['Item1', 'Item2'],
major_axis=pd.date_range('1/1/2000', periods=5),
minor_axis=['A', 'B', 'C', 'D'])
~~~

* 取前5条数据   df.head()   **不传参数默认是5条数据,想取几条就写几**
* 取后5条数据   df.tail()

### 属性和原始ndarra(s)

pandas 对象具有很多属性,让你可以访问元数据:

* shape  :  给出对象的轴尺寸,和ndarray一致
* 轴标签
  * Series      索引仅有轴
  * DataFrame   索引  行和列
  * panel            items     major_axis      minor_axis
* values    获取数据结构中的实际数据

### 加速操作

**pandas支持使用numexpr库和bottleneck库加速某些类型的二进制数值和布尔运算.**

这些库在处理大型数据集时特别有用，并提供大量加速。`numexpr`使用智能分块，缓存和多核。`bottleneck`是一组专门的cython例程，在处理具有的数组时特别快 `nans`。

这是一个示例（使用100列x 100,000行`DataFrames`）：

| 手术        | 0.11.0（ms） | 先前版本（ms） | 比率与先前 |
| ----------- | ------------ | -------------- | ---------- |
| `df1 > df2` | 13.32        | 125.35         | 0.1063     |
| `df1 * df2` | 21.71        | 36.63          | 0.5928     |
| `df1 + df2` | 22.04        | 36.50          | 0.6039     |

### 灵活的二进制操作

通过pandas数据结构之间的二进制操作,有2个关键点

* 高级和低级对象之间的广播行为
* 计算中缺少数据

### 匹配广播行为

数据库所拥有的方法 :

* 加   add()
* 减   sub()
* 乘    mul()
* 除    div()
* divmod()

这些方法都支持axis关键字匹配行和列

### 缺少填充值的数据的操作

**在Series和DataFrame中,算是函数可以选择输入fill_value;即当缺少某个位置的一个值时要替换的值,2个DataFrame都缺少这个值,2个相加 结果是NAN**

### 灵活的比较

**系列和数据帧具有二进制比较方法:**

* eq      写法 :数组.eq(另一个数组)
* ne
* lt
* gt
* le
* ge

### 布尔缩减

**你可以将减少:**

* empty      数组.empty

* any()        (数据==什么).any()

* all()            (数据==什么).any() 

* bool()      在布尔上下文中评估单元素pandas对象的时候,使用   bool()

  ~~~python
  In [52]: pd.Series([True]).bool()
  Out[52]: True
  
  In [53]: pd.Series([False]).bool()
  Out[53]: False
  
  In [54]: pd.DataFrame([[True]]).bool()
  Out[54]: True
  
  In [55]: pd.DataFrame([[False]]).bool()
  Out[55]: False
  ~~~


### 比较对象是否相等

**有一种[`equals()`](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.equals.html#pandas.DataFrame.equals)测试相等性的方法，相应位置的NaN被视为相等。**







~~~python
(df+df).equals(df*2)
True
~~~

### 比较类似数组的对象

**在将pandas数据结构与标量值进行比较时。你可以非常方便的执行元素比较**

~~~python
pd.Series(['foo', 'bar', 'baz']) == 'foo'
“”“
0     True
1    False
2    False
dtype: bool
”“”

~~~

**pandas还处理相同长度的不同类型数组对象之间的元素比较**

~~~python
pd.Series(['foo', 'bar', 'baz']) == pd.Index(['foo', 'bar', 'qux'])
"""
0     True
1     True
2    False
dtype: bool
"""
 pd.Series(['foo', 'bar', 'baz']) == np.array(['foo', 'bar', 'qux'])
"""
0     True
1     True
2    False
dtype: bool
"""
~~~

**Index和Series不同长度的对象比较会引发valueError**

**numpy广播比较，无法广播，会返回False**

~~~python 
np.array([1, 2, 3]) == np.array([1, 2])
"""
False
"""
~~~

### 组合重叠数据集

其中一个DataFrame中的缺失值有条件地填充来自其他DataFrame的类似标记的值。实现此操作的函数是[`combine_first()`](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.combine_first.html#pandas.DataFrame.combine_first)：

~~~python
df1 = pd.DataFrame({'A' : [1., np.nan, 3., 5., np.nan],
  'B' : [np.nan, 2., 3., np.nan, 6.]})


 df2 = pd.DataFrame({'A' : [5., 2., 4., np.nan, 3., 7.],
                    'B' : [np.nan, np.nan, 3., 4., 6., 8.]})


 df1
“”
     A    B
0  1.0  NaN
1  NaN  2.0
2  3.0  3.0
3  5.0  NaN
4  NaN  6.0
“”“
 df2
"""
     A    B
0  5.0  NaN
1  2.0  NaN
2  4.0  3.0
3  NaN  4.0
4  3.0  6.0
5  7.0  8.0
""" 
df1.combine_first(df2)    #用df2中的 数据来填充df1中的缺失值
"""
     A    B
0  1.0  NaN
1  2.0  2.0
2  3.0  3.0
3  5.0  4.0
4  3.0  6.0
5  7.0  8.0
"""
~~~



### 通过DataFrame组合

通过自定义函数来实现上面的功能

~~~python
combiner = lambda x, y: np.where(pd.isna(x), y, x)
df1.combine(df2, combiner)
"""
     A    B
0  1.0  NaN
1  2.0  2.0
2  3.0  3.0
3  5.0  4.0
4  3.0  6.0
5  7.0  8.0
"""
~~~



### 描述性统计

**存在 大量用于在Series,DataFrame,panel上计算描述性统计和其他相关操作的方法,其中大部分是聚合(因此产生低维结果)**

* sum()
* mean()
* quantile()

**其中有些会产生相同大小的物体;一般来说,这些方法采用轴参数**

* cumsum()
* cumprod()

**轴可以通过名称或整数来指定**

* Series    无需轴参数
* DataFrame    index(axis=0),默认是0       'columns'(axis=1)
* panel        'items'(axis=0),   'major'(axis=1,default),   'minor'(axis=2)



**所有的方法都有一个参数,    skipna,用于只是是否排除缺失值.默认情况下是True,排除缺失值.False.不排除缺失值**

~~~python
df
"""
        one       two     three
a -1.101558  1.124472       NaN
b -0.177289  2.487104 -0.634293
c  0.462215 -0.486066  1.931194
d       NaN -0.456288 -1.222918
"""
df.sum(0,skipna=False)

"""
one           NaN
two      2.669223
three         NaN
dtype: float64
"""
df.sum(axis=1, skipna=True)
"""
a    0.022914
b    1.675522
c    1.907343
d   -1.679206
dtype: float64
"""
~~~

**这是常用功能的快速参考汇总表。每个还带有一个可选`level`参数，该参数仅在对象具有[分层索引](http://pandas.pydata.org/pandas-docs/stable/advanced.html#advanced-hierarchical)时才适用 **

| 功能       | 描述                     |
| ---------- | ------------------------ |
| `count`    | 非NA观测数量             |
| `sum`      | 价值总和                 |
| `mean`     | 价值的平均值             |
| `mad`      | 平均绝对偏差             |
| `median`   | 算术值的中值             |
| `min`      | 最低限度                 |
| `max`      | 最大值                   |
| `mode`     | 模式(众数)               |
| `abs`      | 绝对值                   |
| `prod`     | 价值的产物               |
| `std`      | 贝塞尔校正的样本标准偏差 |
| `var`      | 无偏差                   |
| `sem`      | 平均值的标准误差         |
| `skew`     | 样本偏斜（第3时刻）      |
| `kurt`     | 样本峰度（第4个时刻）    |
| `quantile` | 样本分位数（值为％）     |
| `cumsum`   | 累计金额                 |
| `cumprod`  | 累积产品                 |
| `cummax`   | 累积最大值               |
| `cummin`   | 累积最小值               |

* **默认情况下`mean`，某些NumPy方法（例如`std`，和`sum`）将排除系列输入上的NAs**

  ~~~python
  np.mean(df['one'])
  """
  -0.27221094480450114
  """
  np.mean(df['one'].values)
  """
  nan
  """
  ~~~

* **Series.nunique()将返回系列中唯一的非NA值得数量**

  ~~~python
  series = pd.Series(np.random.randn(500))
  series[20:500] = np.nan
  series[10:20]  = 5  
  series.nunique()
  """
  11返回的是非nan数据的格式
  """
  ~~~

### 总结数据: 描述

* 数组.describe()    可以计算有关系列或DataFrame列的各种摘要统计信息(不包括NAN)

* 可以选择要包含在输出中的特定百分位数

  ~~~python
  series.describe(percentiles=[.05,.25,.75,95])
  """
  count    500.000000
  mean      -0.032127
  std        1.067484
  min       -3.463789
  5%        -1.733545
  25%       -0.725523
  50%       -0.053230
  75%        0.679790
  95%        1.854383
  max        3.120271
  dtype: float64
  """
  ~~~




* df.describe()
* df.describe(percentiles=[.05,.25....])  查看指定比例的摘要
* df.describe(include='all/float/int/object')   查看 指定类型的摘要
* df.idxmax()#默认是列    axis=0    返回最大值得索引
* df.idxmin()                                       返回最小值的索引
* df.mode()                                        众数,一维数组,查看一维数组中出现次数最多的那个数

### 离散化和量化

**可以使用[`cut()`](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.cut.html#pandas.cut)（基于值的[`qcut()`](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.qcut.html#pandas.qcut)区间）和（基于样本分位数的区间）功能来对连续值进行离散化：**



**[`qcut()`](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.qcut.html#pandas.qcut)计算样本分位数。例如，我们可以将一些正态分布的数据切割成相等大小的四分位，如下所示：**



**我们还可以传递无限值来定义bin：**

~~~python
arr = np.random.randn(20)
factor = pd.cut(arr, [-np.inf, 0, np.inf])
factor
"""
[(0.0, inf], (0.0, inf], (0.0, inf], (0.0, inf], (-inf, 0.0], ..., (-inf, 0.0], (-inf, 0.0], (0.0, inf], (-inf, 0.0], (0.0, inf]]
Length: 20
Categories (2, interval[float64]): [(-inf, 0.0] < (0.0, inf]]
"""
~~~





### 功能应用

**要将你自己或者其他库的函数应用于pandas对象,有以下3种方法**

1. **表格函数应用:　　　pipe（）**
2. **行或者列方式功能应用：   apply()**
3. **聚合API:                              agg()    transform()**
4. **应用元素函数                       applymap()**



**表格函数应用程序:   pipe()**



**行或列方式函数应用程序**

**可以使用apply()方法沿DataFrame的轴应用任意函数,该方法与描述性统计方法一样,可以采用axis参数**

~~~ 
df.apply(np.mean)  #求平均数   默认时按列
df.apply(np.mean,axis=1)   #按行求平均数
df.apply(lamdbd x:x.max()-x.min())   #通过匿名函数的方式
df.apply(自定义函数)
df.apply('mean')           #还可以调度字符串的方法名称
~~~

**传递的函数的返回类型apply()会影响DataFrame.apply默认行为的最终输出类型**

* 如果应用函数返回 a Series,则最终输出为 a DataFrame;列匹配Series应用函数返回的索引

* 如果应用 函数返回任何其他类型;则最终输出为  a Series

* 次默认行为可以使用被覆盖result_type;它接受三个选项: 

  * reduce
  * broadcast
  * expand

  这些将决定列表喜欢的返回值如何扩展(或者不扩展)到a DataFrame

**apply()结合一些聪明可以用来回答关于数据集的许多问题.例如,可以提取每列最大值得日期**

~~~python
df += pd.DataFrame(np.random.randn(1000, 3), columns=['A', 'B', 'C'],
index=pd.date_range('1/1/2000', periods=1000))
df.apply(lamdba x:x.idxmax())
"""
A   2001-04-25
B   2002-05-31
C   2002-09-25
dtype: datetime64[ns]
"""
"""
自定义函数
"""
def subtract_and_divide(x, sub, divide=1):
    return (x - sub) / divide
df.apply(subtract_and_divide, args=(5,), divide=3)
"""
另一个有用的功能是能够传递Series方法对每个列或行执行一些Series操作：

"""
df.apply(pd.Series.interpolate)
~~~



### 聚合

**聚合API允许用户以简洁的方式表达可能的多个聚合操作。此API在pandas对象中类似，请参阅[groupby API](http://pandas.pydata.org/pandas-docs/stable/groupby.html#groupby-aggregate)， [窗口函数API](http://pandas.pydata.org/pandas-docs/stable/computation.html#stats-aggregate)和[重新采样API](http://pandas.pydata.org/pandas-docs/stable/timeseries.html#timeseries-aggregate)。聚合的入口点是[`DataFrame.aggregate()`](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.aggregate.html#pandas.DataFrame.aggregate)别名 [`DataFrame.agg()`](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.agg.html#pandas.DataFrame.agg)。**

~~~python
"""
求和
"""
df.agg(np.sum)
df.agg('sum')
df.sum

#也适用于Series
df.A.agg('sum')


~~~



#### 聚合多个函数

**你可以将多个聚参数作为列表传递,每个传递函数的结果将是结果中的一个行DataFrame.这些自然地从聚合函数命名**

~~~python
df.agg(['sum'])
"""
            A        B         C
sum  0.835673  4.83851 -0.216025
"""


df.agg(['sum','mean'])   #返回的是DataFrame
"""
             A         B         C
sum   0.835673  4.838510 -0.216025
mean  0.139279  0.806418 -0.036004
"""

df.A.agg(['sum', 'mean'])

"""
Out[161]: 
sum     0.835673
mean    0.139279
Name: A, dtype: float64
"""

#匿名函数
df.A.agg(['sum', lambda x: x.mean()])
"""
sum         0.835673
<lambda>    0.139279
Name: A, dtype: float64
"""

#自定义函数
def mymean(x):
    return x.mean()
df.A.agg(['sum', mymean])

"""
sum       0.835673
mymean    0.139279
Name: A, dtype: float64
"""
~~~



#### 用dict聚合

**将列名称字典传递给标量或标量列表,以DataFrame允许你自定义那些函数应用于那些列,结果如果不是任何特定顺序,可以使用OrderedDict**

~~~python
df.agg({'A':'mean','B':'sum'}) #A列求平均值  B列求和
"""
A    0.139279
B    4.838510
dtype: float64
"""

df.agg({'A': ['mean', 'min'], 'B': 'sum'})#A列求平均值和最小值  B列求和
"""
             A        B
mean  0.139279      NaN
min  -1.874526      NaN
sum        NaN  4.83851
"""
~~~



### 混合Dtypes

**当呈现无法聚合的混合dtypes;agg将仅采用有效聚合;这类似于groupby的agg工作原理**

~~~python
df = pd.DataFrame({
    'A':[1,2,3],
    'B':[1.,2.,3.],
    'C':['foo','bar','baz'],
    'D':pd.data_range('20130301',periods=3)
})
df.dtypes()

"""
A             int64
B           float64
C            object
D    datetime64[ns]
dtype: object
"""

df.agg(['min','sum'])

"""
     A    B          C          D
min  1  1.0        bar 2013-01-01
sum  6  6.0  foobarbaz        NaT
"""
~~~



### 自定义描述

**有.agg()可能轻松创建自定义描述函数,类似于内置的describe函数**

~~~python 
from functools import partial

q_25 = partial(pd.Series.quantile,q=0.25)
q_25.__name__ ='25%'
q_75 = partial(pd.Series.quantile,q=0.75)
q_75.__name__ = '75%'
df.agg(['count','mean','std','min',q_25,'median',q_75,'max'])

"""
               A         B         C
count   6.000000  6.000000  6.000000
mean    0.139279  0.806418 -0.036004
std     1.323362  1.100830  0.874990
min    -1.874526 -0.916844 -1.461363
25%    -0.696544  0.566876 -0.476920
median  0.491354  0.685467  0.183433
75%     1.148055  1.241393  0.601223
max     1.453046  2.430373  0.835024
"""
~~~



### 转换

**该transform()返回一个索引与原始索引相同(大小相同)的对象.次API允许您同时提供多个操作,而不是逐个.**

~~~python
df = pd.DataFrame(np.random.randn(10, 3), columns=['A', 'B', 'C'],index=pd.date_range('1/1/2000', periods=10))

df
"""
                   A         B         C
2000-01-01 -0.578465 -0.503335 -0.987140
2000-01-02 -0.767147 -0.266046  1.083797
2000-01-03  0.195348  0.722247 -0.894537
2000-01-04       NaN       NaN       NaN
2000-01-05       NaN       NaN       NaN
2000-01-06       NaN       NaN       NaN
2000-01-07       NaN       NaN       NaN
2000-01-08 -0.556397  0.542165 -0.308675
2000-01-09 -1.010924 -0.672504 -1.139222
2000-01-10  0.354653  0.563622 -0.365106
"""
~~~

**变换整个帧,transform()允许输入函数为:Numpy函数,字符串 函数名称或用户定义函数**

~~~python
df.transform(np.abs)    #df.transform('abs')   
                        #df.transform(lambda x: x.abs())匿名函数
np.abs(df)
df.A.transform(np.abs)
"""
                   A         B         C
2000-01-01  0.578465  0.503335  0.987140
2000-01-02  0.767147  0.266046  1.083797
2000-01-03  0.195348  0.722247  0.894537
2000-01-04       NaN       NaN       NaN
2000-01-05       NaN       NaN       NaN
2000-01-06       NaN       NaN       NaN
2000-01-07       NaN       NaN       NaN
2000-01-08  0.556397  0.542165  0.308675
2000-01-09  1.010924  0.672504  1.139222
2000-01-10  0.354653  0.563622  0.365106
"""
~~~



#### 用多个函数转换

**传递多个函数将生产列多索引DataFrame.第一级将是原始框架列名称;第二级将是转换函数的名称**

~~~python
df.transform([np.abs,lamdba x:x+1])

"""
                   A                   B                   C          
            absolute  <lambda>  absolute  <lambda>  absolute  <lambda>
2000-01-01  0.578465  0.421535  0.503335  0.496665  0.987140  0.012860
2000-01-02  0.767147  0.232853  0.266046  0.733954  1.083797  2.083797
2000-01-03  0.195348  1.195348  0.722247  1.722247  0.894537  0.105463
2000-01-04       NaN       NaN       NaN       NaN       NaN       NaN
2000-01-05       NaN       NaN       NaN       NaN       NaN       NaN
2000-01-06       NaN       NaN       NaN       NaN       NaN       NaN
2000-01-07       NaN       NaN       NaN       NaN       NaN       NaN
2000-01-08  0.556397  0.443603  0.542165  1.542165  0.308675  0.691325
2000-01-09  1.010924 -0.010924  0.672504  0.327496  1.139222 -0.139222
2000-01-10  0.354653  1.354653  0.563622  1.563622  0.365106  0.634894
"""
~~~

#### 将多个函数传递给Series将产生一个DataFrame.生产的列名将是转换函数.

~~~python
df.A.transform([np.abs, lamdba x:x+1])

"""
            absolute  <lambda>
2000-01-01  0.578465  0.421535
2000-01-02  0.767147  0.232853
2000-01-03  0.195348  1.195348
2000-01-04       NaN       NaN
2000-01-05       NaN       NaN
2000-01-06       NaN       NaN
2000-01-07       NaN       NaN
2000-01-08  0.556397  0.443603
2000-01-09  1.010924 -0.010924
2000-01-10  0.354653  1.354653
"""
~~~



### 用dict转换

#### 通过函数的dict将允许每列选择性转换

~~~python
df.transform(['A':np.abs,'B': lambda x:x+1])

"""
                   A         B
2000-01-01  0.578465  0.496665
2000-01-02  0.767147  0.733954
2000-01-03  0.195348  1.722247
2000-01-04       NaN       NaN
2000-01-05       NaN       NaN
2000-01-06       NaN       NaN
2000-01-07       NaN       NaN
2000-01-08  0.556397  1.542165
2000-01-09  1.010924  0.327496
2000-01-10  0.354653  1.563622
"""
~~~

#### 传递列表的字典将生成具有这些选择性变化的多索引DataFrame

~~~python 
df.transform({'A': np.abs, 'B': [lambda x: x+1, 'sqrt']})

"""
                   A         B          
            absolute  <lambda>      sqrt
2000-01-01  0.578465  0.496665       NaN
2000-01-02  0.767147  0.733954       NaN
2000-01-03  0.195348  1.722247  0.849851
2000-01-04       NaN       NaN       NaN
2000-01-05       NaN       NaN       NaN
2000-01-06       NaN       NaN       NaN
2000-01-07       NaN       NaN       NaN
2000-01-08  0.556397  1.542165  0.736318
2000-01-09  1.010924  0.327496       NaN
2000-01-10  0.354653  1.563622  0.750748
"""
~~~



### 应用元素函数

**由于并非所有函数都可以进行矢量化;因此applymap()DataFrame map()上的方法和类似的Series接受任何Python函数;它接受单个值并返回单个值**

~~~python

~~~














